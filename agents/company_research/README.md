# ğŸ¢ Company Research Agent

**Agent ID:** `agent.mossler.company_research`  
**Version:** 1.0.0  
**Status:** âœ… Registered in Agentify Marketplace

---

## ğŸ“‹ Overview

The Company Research Agent researches company information from websites and enriches Excel data. It extracts:

- **Managing Directors** (GeschÃ¤ftsfÃ¼hrer)
- **Company Size** (Revenue & Employees)
- **Company History** (if available)
- **Current News** (if available)

### Key Features

âœ… **Excel Upload** - Upload Excel files with company data  
âœ… **Gap Analysis** - Automatically identify missing information  
âœ… **Configurable Extraction** - Choose which fields to extract  
âœ… **Web Scraping** - Intelligent scraping with rate limiting  
âœ… **Ethics-First** - Respects robots.txt and rate limits  

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd agents/company_research
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### 3. Run Locally

```bash
python main.py
```

The agent will start on `http://localhost:8000`

### 4. Test the API

```bash
# Health check
curl http://localhost:8000/health

# Get manifest
curl http://localhost:8000/agent/manifest

# Configure fields
curl -X POST http://localhost:8000/company/configure_fields \
  -H "Content-Type: application/json" \
  -d '{
    "managing_directors": true,
    "revenue": true,
    "employees": true,
    "history": false,
    "news": false
  }'
```

---

## ğŸ“– API Endpoints

### Agent Standard Endpoints (Required)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/agent/manifest` | GET | Get agent manifest |
| `/agent/reflect` | POST | Reflect on manifest |
| `/agent/governance` | GET | Get governance map |
| `/agent/collaborators` | GET | List collaborators |

### Company Research Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/company/upload_excel` | POST | Upload Excel file for gap analysis |
| `/company/configure_fields` | POST | Configure extraction fields |
| `/company/research` | POST | Research companies (TODO) |
| `/company/export` | POST | Export enriched data (TODO) |

---

## ğŸ—ï¸ Project Structure

```
agents/company_research/
â”œâ”€â”€ manifest.json          # Agent Standard v1 manifest
â”œâ”€â”€ main.py               # FastAPI server & intents
â”œâ”€â”€ config.py             # Configuration settings
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ register.py           # Marketplace registration script
â”œâ”€â”€ .env.example          # Environment variables template
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ processors/           # Excel processing logic (TODO)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ excel_reader.py
â”‚   â”œâ”€â”€ excel_writer.py
â”‚   â””â”€â”€ gap_analyzer.py
â””â”€â”€ scrapers/             # Web scraping logic (TODO)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ company_scraper.py
    â”œâ”€â”€ data_extractor.py
    â””â”€â”€ llm_extractor.py
```

---

## ğŸ”§ Configuration

Edit `config.py` or set environment variables:

```python
# OpenAI
OPENAI_API_KEY=your_key
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.1

# Web Scraping
RESPECT_ROBOTS_TXT=True
MIN_REQUEST_DELAY=1.0
RATE_LIMIT_REQUESTS=10

# Excel
MAX_FILE_SIZE_MB=50
SUPPORTED_FORMATS=["xlsx", "xls", "csv"]
```

---

## ğŸ“Š Usage Example

```python
import requests

# 1. Configure fields
response = requests.post(
    "http://localhost:8000/company/configure_fields",
    json={
        "managing_directors": True,
        "revenue": True,
        "employees": True,
        "history": False,
        "news": True
    }
)

# 2. Upload Excel file
with open("companies.xlsx", "rb") as f:
    response = requests.post(
        "http://localhost:8000/company/upload_excel",
        files={"file": f}
    )
    gap_analysis = response.json()["gap_analysis"]
    print(f"Missing data for {gap_analysis['incomplete_records']} companies")

# 3. Research companies (TODO)
# 4. Export enriched data (TODO)
```

---

## âœ… Next Steps (Implementation TODO)

- [ ] Implement Excel parsing (`processors/excel_reader.py`)
- [ ] Implement gap analysis (`processors/gap_analyzer.py`)
- [ ] Implement web scraping (`scrapers/company_scraper.py`)
- [ ] Implement LLM-based extraction (`scrapers/llm_extractor.py`)
- [ ] Implement research endpoint (`/company/research`)
- [ ] Implement export endpoint (`/company/export`)
- [ ] Add tests
- [ ] Deploy to Railway

---

## ğŸ”— Links

- **Marketplace:** https://marketplace.meet-harmony.ai
- **Repository:** https://github.com/JonasDEMA/agentify_os
- **Manifest:** [manifest.json](./manifest.json)
- **Agent Standard:** [docs/agent_standard/README.md](../../docs/agent_standard/README.md)

---

**Created:** 2026-01-27  
**Owner:** MÃ¶ÃŸler GmbH

