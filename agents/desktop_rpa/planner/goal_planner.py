"""Goal Planner - Decomposes high-level goals into strategies and actions."""
import logging
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field
from agents.desktop_rpa.cognitive.strategy_manager import Strategy, StrategyManager
from agents.desktop_rpa.cognitive.llm_wrapper import LLMWrapper

logger = logging.getLogger(__name__)

class ExecutionPlan(BaseModel):
    """Represents a plan to achieve a goal."""
    goal: str
    strategy_id: Optional[str] = None
    steps: List[Dict[str, Any]] = Field(default_factory=list)
    reasoning: Optional[str] = None

class GoalPlanner:
    """Orchestrates goal decomposition and strategy selection."""

    def __init__(self, strategy_manager: StrategyManager, llm_wrapper: LLMWrapper):
        """Initialize Goal Planner.

        Args:
            strategy_manager: Manager for learned strategies
            llm_wrapper: Wrapper for LLM interactions
        """
        self.strategy_manager = strategy_manager
        self.llm_wrapper = llm_wrapper

    async def plan_execution(self, goal: str, context: Optional[Dict[str, Any]] = None) -> ExecutionPlan:
        """Create an execution plan for a goal.

        Args:
            goal: High-level goal string
            context: Additional context for planning

        Returns:
            ExecutionPlan instance
        """
        logger.info(f"Planning execution for goal: {goal}")

        # 1. Try to find an existing strategy
        best_strategy = self._find_best_strategy(goal)
        if best_strategy:
            logger.info(f"Found existing strategy: {best_strategy.name}")
            return ExecutionPlan(
                goal=goal,
                strategy_id=best_strategy.strategy_id,
                steps=best_strategy.steps,
                reasoning="Using learned strategy from experience."
            )

        # 2. Ask LLM for a new strategy
        logger.info("No existing strategy found, asking LLM...")
        llm_response = await self.llm_wrapper.ask_for_strategy(goal, context=context)
        
        # Note: In a real implementation, we would validate the LLM response here
        # For now, we assume LLMWrapper returns a valid structure or we map it.
        
        return ExecutionPlan(
            goal=goal,
            steps=llm_response.get("steps", []),
            reasoning=llm_response.get("reasoning", "Generated by LLM.")
        )

    def _find_best_strategy(self, goal: str) -> Optional[Strategy]:
        """Find the most successful learned strategy for a goal."""
        strategies = self.strategy_manager.list_strategies(goal=goal)
        if not strategies:
            return None

        # Sort by success rate and count
        def success_rate(s: Strategy) -> float:
            total = s.success_count + s.failure_count
            if total == 0:
                return 0.5 # Neutral for new strategies
            return s.success_count / total

        # Primary sort: success rate, Secondary sort: execution count
        sorted_strategies = sorted(
            strategies, 
            key=lambda s: (success_rate(s), s.success_count), 
            reverse=True
        )
        
        # Only return if it has a decent success rate or is relatively new
        best = sorted_strategies[0]
        if success_rate(best) >= 0.5:
            return best
            
        return None

    async def decompose_goal(self, goal: str) -> List[str]:
        """Decompose a high-level goal into smaller sub-goals (experimental)."""
        # This would typically involve another LLM call
        prompt = f"Decompose this high-level goal into a list of smaller, discrete sub-goals: {goal}"
        # ... logic to call LLM and parse result ...
        return [goal] # Placeholder
